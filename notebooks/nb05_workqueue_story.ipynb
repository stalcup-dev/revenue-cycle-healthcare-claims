{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee96fc2",
   "metadata": {},
   "source": [
    "# NB-05 Workqueue Story (marts-only)\n",
    "\n",
    "This notebook reads DS3 `mart_workqueue_claims` (and optional DS0) to produce a workqueue memo and preview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06b8e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:06.570136Z",
     "iopub.status.busy": "2026-01-30T21:27:06.569892Z",
     "iopub.status.idle": "2026-01-30T21:27:07.537732Z",
     "shell.execute_reply": "2026-01-30T21:27:07.536898Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d98f45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:07.540534Z",
     "iopub.status.busy": "2026-01-30T21:27:07.540098Z",
     "iopub.status.idle": "2026-01-30T21:27:07.543515Z",
     "shell.execute_reply": "2026-01-30T21:27:07.542887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "QUEUE_CAPACITY = 250\n",
    "TOP_N = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e04e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:07.545897Z",
     "iopub.status.busy": "2026-01-30T21:27:07.545633Z",
     "iopub.status.idle": "2026-01-30T21:27:13.362513Z",
     "shell.execute_reply": "2026-01-30T21:27:13.361903Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\auth\\_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading:   0%|\u001b[32m          \u001b[0m|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading:   0%|\u001b[32m          \u001b[0m|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load marts only (DS3 required, DS0 optional)\n",
    "BQ_PROJECT_ID = os.getenv(\"BQ_PROJECT_ID\") or os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "BQ_DATASET_ID = os.getenv(\"BQ_DATASET_ID\")\n",
    "\n",
    "if not BQ_PROJECT_ID or not BQ_DATASET_ID:\n",
    "    raise RuntimeError(\"BigQuery not configured. Set BQ_PROJECT_ID and BQ_DATASET_ID.\")\n",
    "\n",
    "import pandas_gbq\n",
    "\n",
    "# DS3 required (query top N only)\n",
    "DS3_TABLE = \"mart_workqueue_claims\"\n",
    "\n",
    "required_cols = [\n",
    "    \"desynpuf_id\",\n",
    "    \"clm_id\",\n",
    "    \"at_risk_amt\",\n",
    "    \"denied_potential_allowed_proxy_amt\",\n",
    "    \"payer_allowed_amt\",\n",
    "    \"observed_paid_amt\",\n",
    "    \"payer_yield_gap_amt\",\n",
    "    \"aging_days\",\n",
    "    \"p_denial\",\n",
    "    \"top_denial_group\",\n",
    "    \"top_next_best_action\",\n",
    "    \"top_hcpcs\",\n",
    "    \"top_denial_prcsg\",\n",
    "]\n",
    "\n",
    "select_cols = \", \".join(required_cols)\n",
    "query_ds3 = f\"\"\"\n",
    "SELECT {select_cols}\n",
    "FROM `{BQ_PROJECT_ID}.{BQ_DATASET_ID}.{DS3_TABLE}`\n",
    "ORDER BY at_risk_amt DESC\n",
    "LIMIT {TOP_N}\n",
    "\"\"\"\n",
    "\n",
    "ds3 = pandas_gbq.read_gbq(query_ds3, project_id=BQ_PROJECT_ID)\n",
    "\n",
    "# DS0 optional (receipt only)\n",
    "DS0_TABLE = \"mart_exec_overview_latest_week\"\n",
    "try:\n",
    "    query_ds0 = f\"SELECT week_start, mix_stability_flag FROM `{BQ_PROJECT_ID}.{BQ_DATASET_ID}.{DS0_TABLE}` LIMIT 1\"\n",
    "    ds0 = pandas_gbq.read_gbq(query_ds0, project_id=BQ_PROJECT_ID)\n",
    "except Exception:\n",
    "    ds0 = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b6d53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:13.364673Z",
     "iopub.status.busy": "2026-01-30T21:27:13.364255Z",
     "iopub.status.idle": "2026-01-30T21:27:13.370687Z",
     "shell.execute_reply": "2026-01-30T21:27:13.369903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select ranking metric\n",
    "ranking_metric_used = \"at_risk_amt\" if \"at_risk_amt\" in ds3.columns else None\n",
    "if ranking_metric_used is None:\n",
    "    raise ValueError(\"DS3 missing ranking metric at_risk_amt\")\n",
    "\n",
    "# Sort and select top N\n",
    "queue_df = ds3.sort_values(ranking_metric_used, ascending=False).head(TOP_N).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529eae1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:13.372608Z",
     "iopub.status.busy": "2026-01-30T21:27:13.372341Z",
     "iopub.status.idle": "2026-01-30T21:27:13.380490Z",
     "shell.execute_reply": "2026-01-30T21:27:13.379883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build display columns (omit missing, note omissions)\n",
    "required_order = [\n",
    "    \"desynpuf_id\",\n",
    "    \"clm_id\",\n",
    "    \"at_risk_amt\",\n",
    "    \"denied_potential_allowed_proxy_amt\",\n",
    "    \"payer_allowed_amt\",\n",
    "    \"observed_paid_amt\",\n",
    "    \"payer_yield_gap_amt\",\n",
    "    \"aging_days\",\n",
    "    \"p_denial\",\n",
    "    \"top_denial_group\",\n",
    "    \"top_next_best_action\",\n",
    "    \"top_hcpcs\",\n",
    "    \"top_denial_prcsg\",\n",
    "]\n",
    "\n",
    "present_cols = [c for c in required_order if c in queue_df.columns]\n",
    "missing_cols = [c for c in required_order if c not in queue_df.columns]\n",
    "\n",
    "# Explainability column from marts fields only\n",
    "explain_parts = []\n",
    "for col in [\"top_denial_group\", \"top_next_best_action\", \"top_hcpcs\", \"top_denial_prcsg\"]:\n",
    "    if col in queue_df.columns:\n",
    "        explain_parts.append(col)\n",
    "\n",
    "if explain_parts:\n",
    "    def build_explain(row):\n",
    "        parts = []\n",
    "        if \"top_denial_group\" in explain_parts and pd.notna(row.get(\"top_denial_group\")):\n",
    "            parts.append(str(row.get(\"top_denial_group\")))\n",
    "        if \"top_next_best_action\" in explain_parts and pd.notna(row.get(\"top_next_best_action\")):\n",
    "            parts.append(str(row.get(\"top_next_best_action\")))\n",
    "        if \"top_hcpcs\" in explain_parts and pd.notna(row.get(\"top_hcpcs\")):\n",
    "            parts.append(\"HCPCS \" + str(row.get(\"top_hcpcs\")))\n",
    "        if \"top_denial_prcsg\" in explain_parts and pd.notna(row.get(\"top_denial_prcsg\")):\n",
    "            parts.append(\"PRCSG \" + str(row.get(\"top_denial_prcsg\")))\n",
    "        return \" | \".join(parts) if parts else \"\"\n",
    "\n",
    "    queue_df[\"Explain\"] = queue_df.apply(build_explain, axis=1)\n",
    "    present_cols = present_cols + [\"Explain\"]\n",
    "else:\n",
    "    missing_cols.append(\"Explain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6407ff5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:13.382767Z",
     "iopub.status.busy": "2026-01-30T21:27:13.382537Z",
     "iopub.status.idle": "2026-01-30T21:27:13.391124Z",
     "shell.execute_reply": "2026-01-30T21:27:13.390413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Format for display\n",
    "fmt_df = queue_df[present_cols].copy()\n",
    "\n",
    "money_cols = [\n",
    "    \"at_risk_amt\",\n",
    "    \"denied_potential_allowed_proxy_amt\",\n",
    "    \"payer_allowed_amt\",\n",
    "    \"observed_paid_amt\",\n",
    "    \"payer_yield_gap_amt\",\n",
    "]\n",
    "rate_cols = [\"p_denial\"]\n",
    "\n",
    "for col in money_cols:\n",
    "    if col in fmt_df.columns:\n",
    "        fmt_df[col] = fmt_df[col].apply(lambda v: f\"${float(v):,.0f}\" if pd.notna(v) else \"\")\n",
    "\n",
    "for col in rate_cols:\n",
    "    if col in fmt_df.columns:\n",
    "        fmt_df[col] = fmt_df[col].apply(lambda v: f\"{float(v)*100:,.1f}%\" if pd.notna(v) else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525d25dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:13.393052Z",
     "iopub.status.busy": "2026-01-30T21:27:13.392867Z",
     "iopub.status.idle": "2026-01-30T21:27:14.602812Z",
     "shell.execute_reply": "2026-01-30T21:27:14.602375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\docs\\images\\nb05_workqueue_top25.png\n"
     ]
    }
   ],
   "source": [
    "# Render table to PNG (fallback to CSV if failure)\n",
    "img_dir = Path(\"docs\") / \"images\" if Path(\"docs\").is_dir() else Path(\"..\") / \"docs\" / \"images\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "img_path = img_dir / \"nb05_workqueue_top25.png\"\n",
    "\n",
    "csv_path = Path(\"docs\") / \"workqueue_top25.csv\" if Path(\"docs\").is_dir() else Path(\"..\") / \"docs\" / \"workqueue_top25.csv\"\n",
    "\n",
    "png_written = False\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.axis('off')\n",
    "    table = ax.table(\n",
    "        cellText=fmt_df.values.tolist(),\n",
    "        colLabels=fmt_df.columns.tolist(),\n",
    "        loc='center'\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(7)\n",
    "    table.scale(1, 1.2)\n",
    "    fig.savefig(img_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    png_written = True\n",
    "    print(f\"Wrote {img_path}\")\n",
    "except Exception as exc:\n",
    "    png_written = False\n",
    "    fmt_df.to_csv(csv_path, index=False)\n",
    "    print(f\"PNG render failed; wrote {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab56e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T21:27:14.604410Z",
     "iopub.status.busy": "2026-01-30T21:27:14.604185Z",
     "iopub.status.idle": "2026-01-30T21:27:14.609741Z",
     "shell.execute_reply": "2026-01-30T21:27:14.609372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\docs\\workqueue_memo_latest_week.md\n"
     ]
    }
   ],
   "source": [
    "# Memo export (ASCII-only)\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "anchor_week = \"N/A\"\n",
    "if not ds0.empty and \"week_start\" in ds0.columns:\n",
    "    try:\n",
    "        anchor_week = str(ds0[\"week_start\"].iloc[0])\n",
    "    except Exception:\n",
    "        anchor_week = \"N/A\"\n",
    "\n",
    "fields_omitted_note = \"\"\n",
    "if missing_cols:\n",
    "    fields_omitted_note = \"- Fields omitted: \" + \", \".join(missing_cols)\n",
    "\n",
    "memo_lines = [\n",
    "    \"# Workqueue Memo - Prioritized Claims (Demo)\",\n",
    "    \"\",\n",
    "    \"## What this is\",\n",
    "    \"This is a prioritization demo built from DS3 marts outputs. It is not a guarantee of recoveries.\",\n",
    "    \"\",\n",
    "    \"## Receipt\",\n",
    "    f\"- Anchor week (if DS0 available): {anchor_week}\",\n",
    "    f\"- Ranking basis: {ranking_metric_used}\",\n",
    "    f\"- Top N shown: {TOP_N}\",\n",
    "    f\"- Capacity assumption: {QUEUE_CAPACITY}/day\",\n",
    "    \"- Source: mart_workqueue_claims (DS3)\",\n",
    "    f\"- Generated on: {now}\",\n",
    "    \"\",\n",
    "    \"## Queue preview (Top N)\",\n",
    "]\n",
    "\n",
    "if png_written:\n",
    "    memo_lines.append(\"![Workqueue Top N](images/nb05_workqueue_top25.png)\")\n",
    "else:\n",
    "    memo_lines.append(\"See workqueue_top25.csv\")\n",
    "\n",
    "memo_lines += [\n",
    "    \"\",\n",
    "    \"## How to use this\",\n",
    "    \"- Start with the highest at-risk exposure.\",\n",
    "    \"- Use the explainability columns to route to the correct workflow (action/category).\",\n",
    "    \"- If mix stability is CHECK SEGMENTS in NB-03, treat queue as provisional until drivers are validated.\",\n",
    "    \"\",\n",
    "    \"## Guardrails\",\n",
    "    \"- Proxy values are directional prioritization only; not guaranteed recovery.\",\n",
    "    \"- Paid vs Allowed differences are claim-file amounts used for directional triage, not adjudicated underpayment findings.\",\n",
    "]\n",
    "\n",
    "if fields_omitted_note:\n",
    "    memo_lines.append(\"\")\n",
    "    memo_lines.append(fields_omitted_note)\n",
    "\n",
    "memo_lines = [line.encode(\"ascii\", \"ignore\").decode(\"ascii\") for line in memo_lines]\n",
    "\n",
    "memo_path = Path(\"docs\") / \"workqueue_memo_latest_week.md\" if Path(\"docs\").is_dir() else Path(\"..\") / \"docs\" / \"workqueue_memo_latest_week.md\"\n",
    "with open(memo_path, \"w\", encoding=\"utf-8\") as handle:\n",
    "    handle.write(\"\\n\".join(memo_lines))\n",
    "\n",
    "print(f\"Wrote {memo_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
