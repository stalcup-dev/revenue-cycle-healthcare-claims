{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54d760",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Setup (hidden) ---\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, date, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Toggle for small teaching callouts under key visuals\n",
    "TEACH_MODE = True\n",
    "\n",
    "# Deterministic synthetic data (teaching project)\n",
    "rng = np.random.default_rng(42)\n",
    "GENERATED_AT = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Decision thresholds (single source)\n",
    "SHIFT_THRESHOLD = 0.15\n",
    "PARTIAL_LOW_MAX = 0.10\n",
    "PARTIAL_MED_MAX = 0.20\n",
    "TOP3_SHARE_THRESHOLD = 0.60\n",
    "MIN_DOW_OUTSIDE_BAND = 2\n",
    "SENS_WINDOWS = (6, 8)\n",
    "TRIM_FRACTION = 0.10\n",
    "\n",
    "\n",
    "def partial_week_risk_label(ratio: float) -> str:\n",
    "    if ratio < PARTIAL_LOW_MAX:\n",
    "        return \"LOW\"\n",
    "    if ratio < PARTIAL_MED_MAX:\n",
    "        return \"MED\"\n",
    "    return \"HIGH\"\n",
    "\n",
    "\n",
    "# Synthetic calendar and dataset generation (no hardcoded headline totals)\n",
    "synthetic_anchor_monday = date(2026, 1, 5)\n",
    "this_monday = synthetic_anchor_monday\n",
    "complete_week_starts = [this_monday - timedelta(weeks=w) for w in range(14, 1, -1)]  # 13 complete weeks\n",
    "seed_current_week_start = this_monday - timedelta(weeks=1)\n",
    "seed_partial_week_start = seed_current_week_start + timedelta(days=7)\n",
    "\n",
    "segments = [\"Payer A\", \"Payer B\", \"Payer C\", \"Payer D\", \"Payer E\", \"Payer F\", \"Payer G\"]\n",
    "baseline_shares = np.array([0.30, 0.20, 0.15, 0.10, 0.08, 0.09, 0.08])\n",
    "current_shares = np.array([0.375, 0.19, 0.14, 0.09, 0.075, 0.07, 0.06])\n",
    "\n",
    "\n",
    "def make_week(week_start: date, total: int, shares: np.ndarray, complete: bool = True) -> pd.DataFrame:\n",
    "    dows = np.arange(7)\n",
    "    base = np.array([0.13, 0.15, 0.16, 0.15, 0.14, 0.14, 0.13])\n",
    "    if not complete:\n",
    "        dows = np.arange(4)\n",
    "        base = base[:4] / base[:4].sum()\n",
    "    daily = np.round(total * base).astype(int)\n",
    "    daily[-1] += total - daily.sum()\n",
    "\n",
    "    rows = []\n",
    "    for di, dow in enumerate(dows):\n",
    "        dt = week_start + timedelta(days=int(dow))\n",
    "        seg_counts = np.round(daily[di] * shares).astype(int)\n",
    "        seg_counts[-1] += daily[di] - seg_counts.sum()\n",
    "        for s, v in zip(segments, seg_counts):\n",
    "            rows.append({\"week_start\": week_start, \"date\": dt, \"dow\": int(dow), \"segment\": s, \"volume\": int(v)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "frames = []\n",
    "history_totals = []\n",
    "for ws in complete_week_starts:\n",
    "    total = max(6000, int(rng.normal(7800, 220)))\n",
    "    history_totals.append(total)\n",
    "    frames.append(make_week(ws, total, baseline_shares, complete=True))\n",
    "\n",
    "# Inject a deterministic shift in the latest complete week relative to rolling baseline\n",
    "latest_complete_baseline = int(np.median(history_totals[-8:]))\n",
    "current_total_seed = int(round(latest_complete_baseline * 1.65))\n",
    "frames.append(make_week(seed_current_week_start, current_total_seed, current_shares, complete=True))\n",
    "\n",
    "# Partial week seeded as a fraction of current week to test guardrails\n",
    "partial_total_seed = int(round(current_total_seed * 0.18))\n",
    "frames.append(make_week(seed_partial_week_start, partial_total_seed, current_shares, complete=False))\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Add a small invalid stream (watchlist only)\n",
    "df[\"invalid\"] = rng.binomial(1, 0.012, size=len(df))\n",
    "df[\"invalid_volume\"] = np.where(df[\"invalid\"] == 1, np.minimum(df[\"volume\"], rng.integers(1, 10, size=len(df))), 0)\n",
    "\n",
    "\n",
    "# Anchor and through-date must come from data\n",
    "DATA_THROUGH = pd.to_datetime(df[\"date\"]).max().date().isoformat()\n",
    "raw_current_week_start = pd.to_datetime(df[\"week_start\"]).max().date()\n",
    "week_coverage = (\n",
    "    df.groupby(\"week_start\", as_index=False)[\"dow\"]\n",
    "    .nunique()\n",
    "    .rename(columns={\"dow\": \"dow_count\"})\n",
    ")\n",
    "week_coverage[\"week_start\"] = pd.to_datetime(week_coverage[\"week_start\"]).dt.date\n",
    "coverage_map = dict(zip(week_coverage[\"week_start\"], week_coverage[\"dow_count\"]))\n",
    "\n",
    "# Primary rule: current_week_start is the latest week in data.\n",
    "# If that week is incomplete, treat it as partial and anchor on latest complete week.\n",
    "if coverage_map.get(raw_current_week_start, 0) == 7:\n",
    "    current_week_start = raw_current_week_start\n",
    "    candidate_partial = current_week_start + timedelta(days=7)\n",
    "    if candidate_partial in coverage_map:\n",
    "        partial_week_start = candidate_partial\n",
    "    else:\n",
    "        missing_weeks = sorted([wk for wk, d in coverage_map.items() if d < 7 and wk > current_week_start])\n",
    "        partial_week_start = missing_weeks[0] if missing_weeks else None\n",
    "else:\n",
    "    partial_week_start = raw_current_week_start\n",
    "    complete_prior = sorted([wk for wk, d in coverage_map.items() if d == 7 and wk < raw_current_week_start])\n",
    "    if not complete_prior:\n",
    "        raise RuntimeError(\"No complete week available before partial week in dataset.\")\n",
    "    current_week_start = complete_prior[-1]\n",
    "\n",
    "# Baseline window = last 8 complete weeks before current anchor week\n",
    "complete_weeks_sorted = sorted([wk for wk, d in coverage_map.items() if d == 7 and wk <= current_week_start])\n",
    "if current_week_start not in complete_weeks_sorted:\n",
    "    raise RuntimeError(\"Current anchor week is not complete in this dataset.\")\n",
    "\n",
    "current_idx = complete_weeks_sorted.index(current_week_start)\n",
    "prior_complete_weeks = complete_weeks_sorted[:current_idx]\n",
    "baseline_weeks = prior_complete_weeks[-8:]\n",
    "\n",
    "if len(baseline_weeks) == 0:\n",
    "    raise RuntimeError(\"No prior complete weeks available for baseline.\")\n",
    "\n",
    "\n",
    "def callout(text: str):\n",
    "    if TEACH_MODE:\n",
    "        display(Markdown(f\"> **Interpretation:** {text}\"))\n",
    "\n",
    "\n",
    "def baseline_stat(values: pd.Series, estimator: str) -> float:\n",
    "    s = values.astype(float).sort_values()\n",
    "    if estimator == \"median\":\n",
    "        return float(s.median())\n",
    "    if estimator == \"trimmed_mean\":\n",
    "        k = int(len(s) * TRIM_FRACTION)\n",
    "        if (len(s) - 2 * k) < 1:\n",
    "            return float(s.mean())\n",
    "        return float(s.iloc[k: len(s) - k].mean())\n",
    "    raise ValueError(f\"Unknown estimator: {estimator}\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class State:\n",
    "    decision: str\n",
    "    comparator_validity: str\n",
    "    actionability_status: str\n",
    "    partial_week_ratio: float\n",
    "    partial_week_risk: str\n",
    "    partial_week_numerator: int\n",
    "    partial_week_denominator: int\n",
    "    baseline_week_total: int\n",
    "    current_week_total: int\n",
    "    delta_week: int\n",
    "    delta_per_bus_day: float\n",
    "    volume_shift_flag: bool\n",
    "    history_tier: str\n",
    "    top3_share: float\n",
    "    dow_outside_band_count: int\n",
    "    sensitivity_df: pd.DataFrame\n",
    "    sensitivity_disagreement: bool\n",
    "    flip_conditions: list[str]\n",
    "    disprove_line: str\n",
    "\n",
    "\n",
    "def compute_state() -> State:\n",
    "    weekly_complete = (\n",
    "        df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() <= current_week_start)]\n",
    "        .groupby(\"week_start\", as_index=True)[\"volume\"]\n",
    "        .sum()\n",
    "        .sort_index()\n",
    "    )\n",
    "    weekly_complete.index = pd.to_datetime(weekly_complete.index).date\n",
    "\n",
    "    history = weekly_complete.loc[[wk for wk in weekly_complete.index if wk < current_week_start]]\n",
    "    current_total = int(weekly_complete.loc[current_week_start])\n",
    "    baseline_total = int(round(history.loc[baseline_weeks].median()))\n",
    "    delta_week = int(current_total - baseline_total)\n",
    "    delta_per_day = delta_week / 5.0\n",
    "    pct_delta = (delta_week / baseline_total) if baseline_total else 0.0\n",
    "    volume_shift_flag = abs(pct_delta) >= SHIFT_THRESHOLD\n",
    "\n",
    "    comparator_validity = \"CONFIRMED\" if len(history) >= 1 else \"NOT_CONFIRMED\"\n",
    "\n",
    "    history_count = int(len(history))\n",
    "    if history_count < 13:\n",
    "        history_tier = f\"{history_count}w (LIMITED_CONTEXT)\"\n",
    "    elif history_count < 26:\n",
    "        history_tier = f\"{history_count}w (DIRECTIONAL)\"\n",
    "    else:\n",
    "        history_tier = f\"{history_count}w (ROBUST)\"\n",
    "\n",
    "    if partial_week_start is not None:\n",
    "        partial_total = int(\n",
    "            df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() == partial_week_start)][\"volume\"].sum()\n",
    "        )\n",
    "    else:\n",
    "        partial_total = 0\n",
    "\n",
    "    partial_ratio = (partial_total / current_total) if current_total else 0.0\n",
    "    partial_risk = partial_week_risk_label(partial_ratio)\n",
    "\n",
    "    hist_dow = (\n",
    "        df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() in baseline_weeks)]\n",
    "        .groupby([\"week_start\", \"dow\"], as_index=False)[\"volume\"]\n",
    "        .sum()\n",
    "        .pivot(index=\"week_start\", columns=\"dow\", values=\"volume\")\n",
    "        .reindex(columns=range(7), fill_value=0)\n",
    "    )\n",
    "    q1 = hist_dow.quantile(0.25)\n",
    "    q3 = hist_dow.quantile(0.75)\n",
    "    current_dow = (\n",
    "        df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() == current_week_start)]\n",
    "        .groupby(\"dow\", as_index=True)[\"volume\"]\n",
    "        .sum()\n",
    "        .reindex(range(7), fill_value=0)\n",
    "    )\n",
    "    dow_outside = int(((current_dow < q1) | (current_dow > q3)).sum())\n",
    "\n",
    "    seg_week = (\n",
    "        df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() in (baseline_weeks + [current_week_start]))]\n",
    "        .groupby([\"week_start\", \"segment\"], as_index=False)[\"volume\"]\n",
    "        .sum()\n",
    "    )\n",
    "    seg_week[\"week_start\"] = pd.to_datetime(seg_week[\"week_start\"]).dt.date\n",
    "\n",
    "    baseline_seg = (\n",
    "        seg_week[seg_week[\"week_start\"].isin(baseline_weeks)]\n",
    "        .groupby(\"segment\", as_index=True)[\"volume\"]\n",
    "        .median()\n",
    "        .round()\n",
    "        .astype(int)\n",
    "        .reindex(segments, fill_value=0)\n",
    "    )\n",
    "    current_seg = (\n",
    "        seg_week[seg_week[\"week_start\"] == current_week_start]\n",
    "        .set_index(\"segment\")[\"volume\"]\n",
    "        .reindex(segments, fill_value=0)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "    seg_delta_abs = (current_seg - baseline_seg).abs().sort_values(ascending=False)\n",
    "    total_abs_delta = float(seg_delta_abs.sum())\n",
    "    top3_share = float(seg_delta_abs.head(3).sum() / total_abs_delta) if total_abs_delta else 0.0\n",
    "\n",
    "    rows = []\n",
    "    hist_series = history.copy()\n",
    "    for w in SENS_WINDOWS:\n",
    "        window_values = hist_series.tail(w)\n",
    "        if len(window_values) == 0:\n",
    "            continue\n",
    "        for estimator in (\"median\", \"trimmed_mean\"):\n",
    "            b = baseline_stat(window_values, estimator)\n",
    "            d = current_total - b\n",
    "            pct = (d / b) if b else 0.0\n",
    "            shift = abs(pct) >= SHIFT_THRESHOLD\n",
    "            implied = \"EXPAND_CANDIDATE\" if shift else \"HOLD\"\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"window_weeks\": w,\n",
    "                    \"estimator\": estimator,\n",
    "                    \"baseline_week\": int(round(b)),\n",
    "                    \"delta_pct\": float(pct),\n",
    "                    \"shift_flag\": bool(shift),\n",
    "                    \"implied_decision\": implied,\n",
    "                }\n",
    "            )\n",
    "    sensitivity_df = pd.DataFrame(rows)\n",
    "    sensitivity_disagreement = sensitivity_df[\"shift_flag\"].nunique() > 1 if not sensitivity_df.empty else False\n",
    "\n",
    "    limited_triggers = []\n",
    "    if comparator_validity != \"CONFIRMED\":\n",
    "        limited_triggers.append(\"comparator not confirmed\")\n",
    "    if partial_risk in {\"MED\", \"HIGH\"}:\n",
    "        limited_triggers.append(\"partial-week risk\")\n",
    "    if volume_shift_flag:\n",
    "        limited_triggers.append(\"volume shift trigger\")\n",
    "    if history_count < 13:\n",
    "        limited_triggers.append(\"short history tier\")\n",
    "    if sensitivity_disagreement:\n",
    "        limited_triggers.append(\"sensitivity disagreement\")\n",
    "\n",
    "    actionability = \"LIMITED_CONTEXT\" if limited_triggers else \"STABLE\"\n",
    "    decision = \"HOLD and monitor; reversible actions only.\"\n",
    "    if actionability == \"STABLE\":\n",
    "        decision = \"EXPAND candidate after next confirmed week.\"\n",
    "    if sensitivity_disagreement:\n",
    "        decision = \"HOLD and monitor; sensitivity disagreement locks the decision.\"\n",
    "\n",
    "    pct_now = (delta_week / baseline_total) if baseline_total else 0.0\n",
    "    flip_conditions = [\n",
    "        f\"Next complete+mature week remains >= +15% vs baseline (now: {pct_now*100:.1f}%).\",\n",
    "        f\"Sensitivity panel agrees across 6w/8w and median/trimmed mean (now: {'NO' if sensitivity_disagreement else 'YES'}).\",\n",
    "        f\"DOW divergence persists on >= {MIN_DOW_OUTSIDE_BAND} weekdays outside baseline band (now: {dow_outside}).\",\n",
    "        f\"Top-3 contributors explain >= {TOP3_SHARE_THRESHOLD*100:.0f}% of delta (now: {top3_share*100:.1f}%).\",\n",
    "    ]\n",
    "    disprove_line = (\n",
    "        \"What would disprove this HOLD: all flip conditions are TRUE on the next complete+mature week under the same filters.\"\n",
    "    )\n",
    "\n",
    "    return State(\n",
    "        decision=decision,\n",
    "        comparator_validity=comparator_validity,\n",
    "        actionability_status=actionability,\n",
    "        partial_week_ratio=partial_ratio,\n",
    "        partial_week_risk=partial_risk,\n",
    "        partial_week_numerator=partial_total,\n",
    "        partial_week_denominator=current_total,\n",
    "        baseline_week_total=baseline_total,\n",
    "        current_week_total=current_total,\n",
    "        delta_week=delta_week,\n",
    "        delta_per_bus_day=delta_per_day,\n",
    "        volume_shift_flag=volume_shift_flag,\n",
    "        history_tier=history_tier,\n",
    "        top3_share=top3_share,\n",
    "        dow_outside_band_count=dow_outside,\n",
    "        sensitivity_df=sensitivity_df,\n",
    "        sensitivity_disagreement=sensitivity_disagreement,\n",
    "        flip_conditions=flip_conditions,\n",
    "        disprove_line=disprove_line,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_snapshot_md(state: State) -> str:\n",
    "    lines = [\n",
    "        f\"**Decision:** {state.decision}\",\n",
    "        \"\",\n",
    "        (\n",
    "            f\"**Impact (vs 8w baseline):** Baseline **{state.baseline_week_total:,.0f}/wk** -> \"\n",
    "            f\"Current **{state.current_week_total:,.0f}/wk**  \\n\"\n",
    "            f\"Delta **{state.delta_week:+,.0f}/wk** (about **{state.delta_per_bus_day:+,.0f}/business day**)\"\n",
    "        ),\n",
    "        \"\",\n",
    "        f\"**Comparator validity:** {state.comparator_validity}\",\n",
    "        f\"**Actionability status:** {state.actionability_status}\",\n",
    "        (\n",
    "            f\"**Partial-week risk:** {state.partial_week_risk} \"\n",
    "            f\"({state.partial_week_numerator:,.0f}/{state.partial_week_denominator:,.0f} = {state.partial_week_ratio*100:.1f}%)\"\n",
    "        ),\n",
    "        \"\",\n",
    "        \"**Next actions (reversible):**\",\n",
    "        \"- Validate day-of-week divergence against baseline band.\",\n",
    "        \"- Segment the delta and triage the top contributors.\",\n",
    "        \"- Re-check after the next complete+mature week closes before irreversible actions.\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_receipt_md(state: State) -> str:\n",
    "    return (\n",
    "        f\"Data through: {DATA_THROUGH} | Anchor week: {current_week_start} \"\n",
    "        f\"| Comparator: {state.comparator_validity} | Actionability: {state.actionability_status} \"\n",
    "        f\"| Partial-week risk: {state.partial_week_risk} \"\n",
    "        f\"({state.partial_week_numerator:,.0f}/{state.partial_week_denominator:,.0f} = {state.partial_week_ratio*100:.1f}%) \"\n",
    "        f\"| History tier: {state.history_tier}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def build_decision_md(state: State) -> str:\n",
    "    pct_delta = (state.current_week_total - state.baseline_week_total) / state.baseline_week_total\n",
    "    lines = [\n",
    "        f\"- **Decision:** {state.decision}\",\n",
    "        f\"- **Volume shift trigger:** absolute percent delta >= 15% vs rolling 8-week median baseline (observed: {pct_delta*100:.1f}%).\",\n",
    "        f\"- **Comparator validity gate:** complete+mature comparator is {state.comparator_validity}.\",\n",
    "        f\"- **Actionability rule:** {state.actionability_status}. Use reversible actions only unless all flip conditions pass.\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def assert_message_consistency(state: State, snapshot_md: str, receipt_md: str, decision_md: str) -> None:\n",
    "    assert state.decision in snapshot_md, \"Snapshot drift: decision text mismatch\"\n",
    "    assert state.decision in decision_md, \"Decision slide drift: decision text mismatch\"\n",
    "    assert f\"Actionability: {state.actionability_status}\" in receipt_md, \"Receipt drift: actionability mismatch\"\n",
    "    pr = f\"{state.partial_week_risk} ({state.partial_week_numerator:,.0f}/{state.partial_week_denominator:,.0f}\"\n",
    "    assert pr in snapshot_md, \"Snapshot drift: partial-week ratio mismatch\"\n",
    "    assert pr in receipt_md, \"Receipt drift: partial-week ratio mismatch\"\n",
    "\n",
    "\n",
    "def build_export_receipt(state: State) -> str:\n",
    "    return (\n",
    "        \"**Export receipt:** \"\n",
    "        f\"run {GENERATED_AT} | data_through {DATA_THROUGH} | \"\n",
    "        f\"anchor_week {current_week_start} | baseline {state.baseline_week_total:,.0f} | \"\n",
    "        f\"current {state.current_week_total:,.0f} | delta {state.delta_week:+,.0f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "state = compute_state()\n",
    "export_receipt_md = build_export_receipt(state)\n",
    "snapshot_md = \"\"\n",
    "receipt_md = \"\"\n",
    "decision_md = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90081ea9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Queue Volume Shift Brief (v1.6)\n",
    "\n",
    "*Operator decision brief for weekly queue volume shifts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53846c32",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(Markdown(f\"**Data through:** {DATA_THROUGH}  \\n**Generated:** {GENERATED_AT}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a66fb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executive Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e3a53",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "snapshot_md = build_snapshot_md(state)\n",
    "display(Markdown(snapshot_md))\n",
    "callout(\"Decision remains HOLD unless persistence is confirmed under the same comparator-valid conditions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6b9a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Executive Translation (plain English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92de74e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lines = [\n",
    "\"- **Baseline** = the typical weekly volume (rolling 8-week median).\",\n",
    "\"- **Current** = the latest complete + mature week we trust for decisions.\",\n",
    "\"- **Partial-week activity** = the current in-progress week (can be misleading).\",\n",
    "\"- **Comparator validity** = we have a complete week to compare against baseline (apples-to-apples).\",\n",
    "\"- **Actionability status (LIMITED_CONTEXT)** = we treat the signal as real enough to investigate, not real enough for irreversible changes.\",\n",
    "\"- **Load multiple** = current ÷ baseline (how many times larger than normal).\",\n",
    "]\n",
    "display(Markdown(\"\\n\".join(lines)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a7a80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Micro glossary (6 terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663c171",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "items = [\n",
    "\"- **Complete week:** 7/7 days present for the anchor week.\",\n",
    "\"- **Mature gate:** in real ops, use settled/adjudicated window (e.g., 45+ days) before trusting volume.\",\n",
    "\"- **Rolling 8-week median:** robust baseline resistant to one-off spikes.\",\n",
    "\"- **Partial-week ratio:** partial-week volume ÷ anchor week volume.\",\n",
    "\"- **Actionability status:** STABLE / INVESTIGATE / LIMITED_CONTEXT (drives reversible vs irreversible actions).\",\n",
    "\"- **Other (mix shift):** remainder outside Top-N segments, aggregated so totals reconcile.\",\n",
    "]\n",
    "display(Markdown(\"\\n\".join(items)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da93ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data contract (required fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c00e0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    {\"Field\":\"week_start\", \"Alt name\":\"—\", \"Required?\":\"Yes\", \"Type\":\"date\", \"Used for\":\"weekly rollups + baselines\"},\n",
    "    {\"Field\":\"date\", \"Alt name\":\"—\", \"Required?\":\"Yes\", \"Type\":\"date\", \"Used for\":\"day-of-week ramp\"},\n",
    "    {\"Field\":\"dow\", \"Alt name\":\"day_of_week\", \"Required?\":\"Yes\", \"Type\":\"int (0-6)\", \"Used for\":\"DOW comparisons + bands\"},\n",
    "    {\"Field\":\"segment\", \"Alt name\":\"payer / lob / driver\", \"Required?\":\"Yes\", \"Type\":\"string\", \"Used for\":\"segment deltas + mix shift\"},\n",
    "    {\"Field\":\"volume\", \"Alt name\":\"count\", \"Required?\":\"Yes\", \"Type\":\"int\", \"Used for\":\"all volume KPIs\"},\n",
    "    {\"Field\":\"invalid_volume\", \"Alt name\":\"—\", \"Required?\":\"No\", \"Type\":\"int\", \"Used for\":\"data quality watchlist (materiality gating)\"},\n",
    "    {\"Field\":\"invalid\", \"Alt name\":\"invalid_flag\", \"Required?\":\"No\", \"Type\":\"0/1\", \"Used for\":\"invalid reason drilldown (optional)\"},\n",
    "]\n",
    "dfc = pd.DataFrame(rows)\n",
    "display(dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51dc71c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Impact translation (baseline vs current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6c2dc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Bars: baseline vs current\n",
    "fig, ax = plt.subplots(figsize=(8.5,4.5))\n",
    "ax.bar([\"Baseline (8w median)\",\"Current (complete+mature)\"], [state.baseline_week_total, state.current_week_total])\n",
    "ax.set_ylabel(\"Weekly volume\")\n",
    "ax.set_title(\"Weekly volume: baseline vs current\")\n",
    "for i,v in enumerate([state.baseline_week_total, state.current_week_total]):\n",
    "    ax.text(i, v, f\"{v:,.0f}\", ha=\"center\", va=\"bottom\")\n",
    "ax.text(0.5, max(state.baseline_week_total, state.current_week_total)*0.85,\n",
    "        f\"Delta {state.delta_week:+,.0f}/wk  ({state.delta_per_bus_day:+,.0f}/business day)\",\n",
    "        ha=\"center\")\n",
    "plt.show()\n",
    "callout(\"Use this slide to size the magnitude. Percent change is secondary; the actionable number is delta per day.\")\n",
    "\n",
    "# Load multiple + ops-load sizing (realistic bands)\n",
    "load_multiple = state.current_week_total / state.baseline_week_total\n",
    "assumed = [500, 1000, 2500, 5000]\n",
    "tbl=[]\n",
    "for tp in assumed:\n",
    "    net = state.delta_per_bus_day - tp\n",
    "    tbl.append([tp, f\"{net:+,.0f}\"])\n",
    "out = pd.DataFrame(tbl, columns=[\"Assumed throughput/day\",\"Net backlog change/day\"])\n",
    "display(Markdown(f\"Load multiple ? **{load_multiple:.2f}x** (current ? baseline).\"))\n",
    "display(Markdown(\"(Use delta/day for sizing; this is not a staffing recommendation.)\"))\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008be46d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validity Receipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8367f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "receipt_md = build_receipt_md(state)\n",
    "display(Markdown(receipt_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52338ae2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Week completeness ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2771f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Baseline DOW band (median + IQR) across baseline weeks\n",
    "baseline_weeks_df = df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() in baseline_weeks)]\n",
    "dow_base = baseline_weeks_df.groupby([\"week_start\", \"dow\"])[\"volume\"].sum().reset_index()\n",
    "\n",
    "med = dow_base.groupby(\"dow\")[\"volume\"].median()\n",
    "q1 = dow_base.groupby(\"dow\")[\"volume\"].quantile(0.25)\n",
    "q3 = dow_base.groupby(\"dow\")[\"volume\"].quantile(0.75)\n",
    "\n",
    "cur = (\n",
    "    df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() == current_week_start)]\n",
    "    .groupby(\"dow\")[\"volume\"]\n",
    "    .sum()\n",
    "    .reindex(range(7), fill_value=0)\n",
    ")\n",
    "\n",
    "cum_med = med.cumsum()\n",
    "cum_q1 = q1.cumsum()\n",
    "cum_q3 = q3.cumsum()\n",
    "cum_cur = cur.cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "ax.plot(cum_med.index, cum_med.values, marker=\"o\", label=\"Baseline median (cum)\")\n",
    "ax.fill_between(cum_med.index, cum_q1.values, cum_q3.values, alpha=0.2, label=\"Baseline IQR band\")\n",
    "ax.plot(cum_cur.index, cum_cur.values, marker=\"o\", label=\"Current (cum)\")\n",
    "ax.set_xticks(range(7))\n",
    "ax.set_xticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n",
    "ax.set_ylabel(\"Cumulative volume\")\n",
    "ax.set_title(\"Cumulative volume by day-of-week vs baseline band\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "diff = (cur - med).sort_values(ascending=False)\n",
    "top = diff.head(2)\n",
    "callout(\n",
    "    f\"Largest positive divergence days: {', '.join([['Mon','Tue','Wed','Thu','Fri','Sat','Sun'][i] for i in top.index])}. \"\n",
    "    \"Confirm if pattern persists in next complete week.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c954a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Segment drivers + mix shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053b1f2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Segment totals for baseline vs current (fully data-derived)\n",
    "seg_week = (\n",
    "    df[df[\"week_start\"].apply(lambda d: pd.to_datetime(d).date() in (baseline_weeks + [current_week_start]))]\n",
    "    .groupby([\"week_start\", \"segment\"], as_index=False)[\"volume\"]\n",
    "    .sum()\n",
    ")\n",
    "seg_week[\"week_start\"] = pd.to_datetime(seg_week[\"week_start\"]).dt.date\n",
    "\n",
    "baseline_seg = (\n",
    "    seg_week[seg_week[\"week_start\"].isin(baseline_weeks)]\n",
    "    .groupby(\"segment\", as_index=True)[\"volume\"]\n",
    "    .median()\n",
    "    .round()\n",
    "    .astype(int)\n",
    ")\n",
    "current_seg = (\n",
    "    seg_week[seg_week[\"week_start\"] == current_week_start]\n",
    "    .set_index(\"segment\")[\"volume\"]\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "all_segments = sorted(set(baseline_seg.index).union(set(current_seg.index)))\n",
    "baseline_seg = baseline_seg.reindex(all_segments, fill_value=0)\n",
    "current_seg = current_seg.reindex(all_segments, fill_value=0)\n",
    "\n",
    "delta = (current_seg - baseline_seg).sort_values(ascending=False)\n",
    "topN = min(3, len(delta))\n",
    "top = delta.head(topN)\n",
    "other = delta.iloc[topN:]\n",
    "other_total = int(other.sum()) if len(other) else 0\n",
    "\n",
    "contrib = pd.DataFrame(\n",
    "    {\n",
    "        \"Segment\": list(top.index) + ([\"Other\"] if len(other) else []),\n",
    "        \"Delta (current - baseline)\": list(top.values) + ([other_total] if len(other) else []),\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "ax.bar(contrib[\"Segment\"], contrib[\"Delta (current - baseline)\"])\n",
    "ax.set_ylabel(\"Delta volume\")\n",
    "ax.set_title(\"Top contributors to delta (Top-3 + Other)\")\n",
    "for i, v in enumerate(contrib[\"Delta (current - baseline)\"]):\n",
    "    ax.text(i, v, f\"{v:,.0f}\", ha=\"center\", va=\"bottom\")\n",
    "plt.show()\n",
    "\n",
    "mix = pd.DataFrame(\n",
    "    {\n",
    "        \"Segment\": all_segments,\n",
    "        \"Baseline share\": (baseline_seg / max(1, baseline_seg.sum())).values,\n",
    "        \"Current share\": (current_seg / max(1, current_seg.sum())).values,\n",
    "    }\n",
    ")\n",
    "mix[\"Delta share (pp)\"] = (mix[\"Current share\"] - mix[\"Baseline share\"]) * 100\n",
    "mix_sort = mix.sort_values(\"Current share\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "ax.bar(mix_sort[\"Segment\"], mix_sort[\"Baseline share\"] * 100, label=\"Baseline\")\n",
    "ax.bar(mix_sort[\"Segment\"], mix_sort[\"Current share\"] * 100, alpha=0.7, label=\"Current\")\n",
    "ax.set_ylabel(\"Share of weekly volume (%)\")\n",
    "ax.set_title(\"Mix shift: baseline vs current share\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "other_segments = list(other.index)\n",
    "top_inside_other = other.abs().sort_values(ascending=False).head(2).index.tolist() if len(other) else []\n",
    "if len(other):\n",
    "    display(\n",
    "        Markdown(\n",
    "            f\"Other = all remaining segments outside Top-N ranked by |delta| (N={len(other_segments)}). \"\n",
    "            f\"Top contributors inside Other: {', '.join(top_inside_other)}.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "display(Markdown(f\"Drivers shown: {topN} (of {len(all_segments)}).\"))\n",
    "\n",
    "callout(\"Use this slide to answer: where the delta comes from and whether composition changed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe41158",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision + trigger rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde80cba",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "decision_md = build_decision_md(state)\n",
    "display(Markdown(decision_md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f74a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Standard (HOLD -> EXPAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4009acf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "criteria_lines = [\"- **Flip HOLD -> EXPAND only if ALL conditions are TRUE on the next complete+mature week:**\"]\n",
    "for idx, cond in enumerate(state.flip_conditions, start=1):\n",
    "    criteria_lines.append(f\"  {idx}) {cond}\")\n",
    "criteria_lines.append(\"\")\n",
    "criteria_lines.append(\"- **If any condition fails:** HOLD remains locked.\")\n",
    "criteria_lines.append(f\"- **What would disprove this?** {state.disprove_line}\")\n",
    "\n",
    "if state.sensitivity_disagreement:\n",
    "    criteria_lines.append(\"- **Sensitivity verdict:** DISAGREEMENT detected; HOLD is locked until methods agree.\")\n",
    "else:\n",
    "    criteria_lines.append(\"- **Sensitivity verdict:** Agreement detected across methods.\")\n",
    "\n",
    "sensitivity_panel = state.sensitivity_df.copy()\n",
    "sensitivity_panel[\"delta_pct\"] = (sensitivity_panel[\"delta_pct\"] * 100).round(1)\n",
    "sensitivity_panel = sensitivity_panel.rename(\n",
    "    columns={\n",
    "        \"window_weeks\": \"Window\",\n",
    "        \"estimator\": \"Estimator\",\n",
    "        \"baseline_week\": \"Baseline/wk\",\n",
    "        \"delta_pct\": \"Delta %\",\n",
    "        \"shift_flag\": \"Shift >=15%\",\n",
    "        \"implied_decision\": \"Implied decision\",\n",
    "    }\n",
    ")\n",
    "\n",
    "display(Markdown(\"\\n\".join(criteria_lines)))\n",
    "display(sensitivity_panel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b9e11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Appendix: Data Quality Watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3aa89",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# KPI card style outputs (materiality gated)\n",
    "week = df[df[\"week_start\"]==current_week_start]\n",
    "invalid_total = int(week[\"invalid_volume\"].sum())\n",
    "week_total = int(week[\"volume\"].sum())\n",
    "rate = invalid_total / max(1, week_total)\n",
    "\n",
    "display(Markdown(f\"**Invalid volume (anchor week):** {invalid_total:,.0f}  \\n**Invalid rate:** {rate*100:.2f}%\"))\n",
    "if rate >= 0.05:\n",
    "    display(Markdown(\"?? **ALERT:** invalid rate breaches 5% threshold - investigate before trusting deltas.\"))\n",
    "else:\n",
    "    display(Markdown(\"No alert: invalids are below materiality threshold; monitor only.\"))\n",
    "\n",
    "tri = week.groupby(\"segment\")[[\"invalid_volume\",\"volume\"]].sum().reset_index()\n",
    "tri[\"invalid_rate_%\"] = (tri[\"invalid_volume\"] / tri[\"volume\"] * 100).round(2)\n",
    "tri = tri.sort_values([\"invalid_volume\"], ascending=False).head(5)\n",
    "display(tri)\n",
    "\n",
    "display(Markdown(export_receipt_md))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62425682",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hidden QC and publish guardrail: execute asserts, never render in exported deck\n",
    "assert_message_consistency(state, snapshot_md, receipt_md, decision_md)\n",
    "if state.sensitivity_disagreement:\n",
    "    assert \"HOLD\" in state.decision, \"Sensitivity disagreement must force HOLD.\"\n",
    "assert \"Export receipt:\" in export_receipt_md, \"Export receipt missing\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  },
  "livereveal": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
